# qa_with_AI_Agent â€” RAG (Retrieval-Augmented Generation) Pipeline

A complete RAG (Retrieval-Augmented Generation) pipeline built with:

* âœ… Multiple document loader support (PDF, TXT, CSV, DOCX, XLSX)
* âœ… Chunking using LangChain text splitters
* âœ… Local embeddings using `SentenceTransformer` (`all-MiniLM-L6-v2`)
* âœ… Chroma Vector Database for semantic search
* âœ… Gemini 2.5 Flash for answer generation
* âœ… RAG Pipeline â†’ **PLAN â†’ RETRIEVE â†’ ANSWER â†’ REFLECT**
* âœ… Works on **Windows / Linux / Mac** â€” No GPU needed


## Architecture Flow

```
User Question
â†“
[ PLAN ]
â†“
[ RETRIEVE ] â†’ (using Chroma + MiniLM embeddings)
â†“
[ ANSWER ] â†’ (Gemini 2.5 Flash LLM Output)
â†“
[ REFLECT ] â†’ (Relevance evaluation)
â†“
Final Output (Answer + Reflection + Sources)
```

## ğŸ“ Project Structure

```
qa_with_AI_Agent/
â”‚
â”œâ”€â”€ data/ # PDFs, TXT docs
â”œâ”€â”€ chroma_store/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_loader.py # Loads docs
â”‚ â”œâ”€â”€ embedding.py # Chunk + embedding generation
â”‚ â”œâ”€â”€ vectorstore.py # Chroma DB wrapper
â”‚ â”œâ”€â”€ search.py # Retrieval + LLM answering
â”‚ â”œâ”€â”€ agent.py # PLAN â†’ RETRIEVE â†’ ANSWER â†’ REFLECT
â”‚
â”œâ”€â”€ ingest.py # Build vector DB
â”œâ”€â”€ app.py
â”œâ”€â”€ main_app.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Setup

### Prerequisites

* Python 3.9+
* `git` installed
* Internet access for downloading packages and for the Gemini API

### Create Virtual Environment & Install Dependencies

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Mac/Linux
source venv/bin/activate

pip install -r requirements.txt
```

### Add API key

Create `.env` in project root:

```bash
GOOGLE_API_KEY=your_api_key_here
```


## ğŸ” Clone the repository

You can clone this repository using HTTPS or SSH. Replace the URL below with the repository URL if you have forked it.

**Using HTTPS**

```bash
git clone https://github.com/jbittu/qa_with_AI_Agent.git
cd qa_with_AI_Agent
```

**Using SSH** (requires SSH key setup in your GitHub account)

```bash
git clone git@github.com:jbittu/qa_with_AI_Agent.git
cd qa_with_AI_Agent
```

If you want to contribute, it's a good idea to create a feature branch:

```bash
git checkout -b feat/your-feature-name
```

## ğŸ—‚ Ingest Documents

Add files to the `data/` folder (PDF/TXT/CSV/DOCX/XLSX), then run:

```bash
python ingest.py
```

You should see:

```
âœ… Embeddings generated
âœ… Chroma DB created at: chroma_store
```

---

## 4ï¸âƒ£ Run CLI Version

```bash
python app.py
```

## ğŸ–¥ Run Streamlit UI

```bash
streamlit run main_app.py
```

**Deployed Streamlit demo (if available):**

* Add your Streamlit deployment URL here (e.g. `https://ragwithpdfapplication.streamlit.app/`) to share a live demo.

## âœ… Try asking

```bash
- "What are the drawbacks of climate change?"
- "What is machine learning and its features?"
```

## ğŸ”§ Features

| Feature                            | Status |
| ---------------------------------- | ------ |
| Load multiple document formats     | âœ…      |
| SentenceTransformer Embeddings     | âœ…      |
| Chroma Vector DB (persisted)       | âœ…      |
| Gemini 2.5 Flash LLM RAG Answering | âœ…      |
| Reflection score on relevance      | âœ…      |
| Streamlit Web UI                   | âœ…      |


##  Contributing

Contributions welcome! Please open issues or PRs. Suggested workflow:

1. Fork the repo
2. Create a feature branch (`git checkout -b feat/my-feature`)
3. Commit and push
4. Open a Pull Request


## ğŸ”— Links

* Repository: `https://github.com/jbittu/qa_with_AI_Agent`
